# Python-LLM Multi-Agent System

A comprehensive Python 3.12 codebase featuring multiple AI agents and LLM-powered tools for various applications.

## ğŸš€ Features

- **Multi-Agent Conversations**: AutoGen-based agent interactions
- **Reflection Agents**: LangGraph-powered self-improving agents
- **Search Agents**: Web scraping and search capabilities
- **News Summarization**: Automated crypto news analysis
- **Expert Interview System**: AI-powered technical interview tools
- **Embedding Systems**: ChromaDB-based document retrieval
- **Template Chains**: Reusable LLM prompt templates

## ğŸ“ Project Structure

```
Python-LLM/
â”œâ”€â”€ agents.py                 # AutoGen agent definitions
â”œâ”€â”€ multi_agents_talk.py      # Multi-agent conversation system
â”œâ”€â”€ reflect_agent.py          # LangGraph reflection agent
â”œâ”€â”€ search_agent.py           # Web search and browser automation
â”œâ”€â”€ news_summariser.py        # Crypto news scraping and analysis
â”œâ”€â”€ embedding.py              # ChromaDB embedding system
â”œâ”€â”€ template_chain.py         # LLM template chains
â”œâ”€â”€ prompts.py                # LangChain prompt templates
â”œâ”€â”€ utils.py                  # Configuration utilities
â”œâ”€â”€ const.py                  # Constants and settings
â”œâ”€â”€ expert_interview/         # Expert interview module
â”‚   â”œâ”€â”€ interviewer.py        # Main interviewer class
â”‚   â”œâ”€â”€ templates.py          # Interview templates
â”‚   â”œâ”€â”€ qa_guide.md          # Q&A interview guide
â”‚   â””â”€â”€ README.md            # Module documentation
â”œâ”€â”€ news/                     # Generated news files
â”œâ”€â”€ docs/                     # Documentation
â””â”€â”€ requirements.txt          # Python dependencies
```

## ğŸ› ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd Python-LLM
   ```

2. **Create virtual environment**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up Ollama** (for local LLM models)
   ```bash
   # Install Ollama and download models
   ollama pull qwen2.5-coder:32b
   ollama pull llama3.2
   ```

## ğŸ¯ Quick Start

### Expert Interview System
```python
from expert_interview import ExpertInterviewer

interviewer = ExpertInterviewer()
questions = interviewer.generate_questions()
print(questions)
```

### Multi-Agent Conversations
```python
from multi_agents_talk import process

result = process("Your task description here")
print(result)
```

### News Summarization
```python
from news_summariser import news_payload

news_data = news_payload()
print(news_data)
```

## ğŸ”§ Configuration

- **API Keys**: Set your own API keys for external services
- **Ollama Models**: Configure local LLM models in `utils.py`
- **Agent Settings**: Customize agent behaviors in `const.py`

## ğŸ“š Documentation

- **Expert Interview Module**: See `expert_interview/README.md`
- **Agent System**: Check `agents.py` and `multi_agents_talk.py`
- **Template System**: Review `template_chain.py` and `prompts.py`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.